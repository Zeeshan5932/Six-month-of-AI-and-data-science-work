{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 About Data\n",
    "- Data: Apple Store Data\n",
    "- Data age: This data was collected in October 2023\n",
    "- Dataset : [:link:](https://www.kaggle.com/datasets/gauthamp10/apple-appstore-apps)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Context\n",
    "    Apple AppStore Android App Data. (1.2 Million+ App Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content\n",
    "     I've collected the data with the help of Python script (Scrapy) running on a cluster of cloud vm instances.\n",
    "    The data was collected in the month of October 2021.\n",
    "\n",
    "- Also checkout:\n",
    "\n",
    "Google Play Store Apps dataset:[link](https://www.kaggle.com/gauthamp10/google-playstore-apps)\n",
    "\n",
    "Android App Permission dataset:[link](https://www.kaggle.com/gauthamp10/app-permissions-android)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Acknowledgements\n",
    "I couldn't have build this dataset without the help of Github Education."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4 Kernel Version Used\n",
    "- Python 3.11.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3.0 Import Libraries\n",
    "- We will use the follwoing libraries\n",
    "  \n",
    "    1- Pandas: Data manipulation and analysis library.\n",
    "\n",
    "    2- Numpy: Numerical computing library.\n",
    "\n",
    "    3- Matplotlib: Data visualization library.\n",
    "    \n",
    "    4- Seaborn: Statistical data visualization library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Visulization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 Data Exploration & Wrangling\n",
    "\n",
    " We will use the following processed\n",
    "\n",
    " # 4.1 Loading the csv file in pandas\n",
    "\n",
    "# 4.2  Creating the dataframe and understanding the data present in the dataset:\n",
    "# 4.3 Handling missing values using different methods:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\DS & ai\\06_Apple_EDA.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DS%20%26%20ai/06_Apple_EDA.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Load Dataset\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/DS%20%26%20ai/06_Apple_EDA.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mD:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mDS & ai\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mData/06_Apple_EDA.csv\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "df = pd.read_csv(\"D:\\DS & ai\\Data/06_Apple_EDA.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Read data succesfully*\n",
    "- Rows: 1230376\n",
    "- Columns: 21 \n",
    "- Total = 25837896"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4 Analyze and describe Data\n",
    "   we using sneak peak..This way we can easily check the null values & summerize them....\n",
    "   Sneak peak use to show specific columns & Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important Thing\n",
    "1. The first thing you need to do is to understand the problem and its requirements. This means that you should read all the instructions, guidel\n",
    "2. The second way to fix maximum Row and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Option to be max for Rows and Columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "# hide all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lets have a look to top rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific data\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print row and column count in the dataset\n",
    "print('Number of rows in the dataset : ', df.shape[0])\n",
    "print('Number of columns in the dataset : ', df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descrpitive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summerize data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Observations**\n",
    "---\n",
    "1. There are 1230376 rows and 21 columns in the dataset\n",
    "2. The columns are of different data types\n",
    "3. The columns in the datasets are:\n",
    "   - `''App_Id', 'App_Name', 'AppStore_Url', 'Primary_Genre', 'Content_Rating',\n",
    "       'Size_Bytes', 'Required_IOS_Version', 'Released', 'Updated', 'Version',\n",
    "       'Price', 'Currency', 'Free', 'DeveloperId', 'Developer',\n",
    "       'Developer_Url', 'Developer_Website', 'Average_User_Rating', 'Reviews',\n",
    "       'Current_Version_Score', 'Current_Version_Reviews''`\n",
    "4. There are some missing values in the dataset which we will read in details and deal later on in the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing vvalues in dataset\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw heatmap of the entire dataframe \n",
    "sns.heatmap(df.isnull(), yticklabels=False, cbar=False, cmap='viridis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check percentage of missing values\n",
    "missing_percentage = df.isnull().sum().sort_values(ascending=False)/df.shape[0]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We will generate a graphical representation of the percentage of null values by plotting the data using an appropriate charting technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_percentage = missing_percentage[missing_percentage != 0] # Only the missing data\n",
    "plt.rcParams['figure.figsize'] = (20,6)\n",
    "missing_percentage.plot(kind = 'barh')\n",
    "plt.title(\"Percentage of null values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation set : 4\n",
    "\n",
    " We Dealing with Null values\n",
    "\n",
    "1 . The columns having highest percentage of null values is :\\\n",
    "\n",
    " Developer website "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Developer_Website' , axis= 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation Set 4:\n",
    "\n",
    "Price, Size_Bytes are important columns so it is good to fill the null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing values dealing\n",
    "#filling mean value of Price column in the null places of that column\n",
    "\n",
    "df['Price']= df.Price.fillna(value=df['Price'].mean())\n",
    "df['Size_Bytes'] = df.Size_Bytes.fillna(value=df['Size_Bytes'].mean())\n",
    "\n",
    "# View fill new data again\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # To view only those rows where a column has null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Developer_Url'].isnull()].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Released'].isnull()].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['App_Name'].isnull()].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['Developer_Url'], inplace=True)\n",
    "df.dropna(subset=['Released'], inplace=True)\n",
    "df.dropna(subset=['App_Name'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##have a view of refreshed dataset again\n",
    "df.isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 1: we Clean the data from null values\n",
    "    Now we deal with duplicates Value in our dataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We check duplicates Values in dataset\n",
    "df.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "any_duplicates = df.duplicated(subset=['App_Id', 'App_Name', 'AppStore_Url', 'Primary_Genre', 'Content_Rating',\n",
    "       'Size_Bytes', 'Required_IOS_Version', 'Released', 'Updated', 'Version',\n",
    "       'Price', 'Currency', 'Free', 'DeveloperId', 'Developer',\n",
    "       'Developer_Url', 'Average_User_Rating', 'Reviews',\n",
    "       'Current_Version_Score', 'Current_Version_Reviews']).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean = df['App_Name'].duplicated().any()\n",
    "boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['App_Name'].value_counts().sort_values(ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
