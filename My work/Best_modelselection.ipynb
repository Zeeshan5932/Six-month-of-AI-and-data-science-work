{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Train Test split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "\n",
    "# Models for regreesion\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
    "from scipy.stats import randint\n",
    "\n",
    "\n",
    "\n",
    "#import grid search cv for cross validation\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "\n",
    "# import preprocessors\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Don't show warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ***First of all  we can Import libraries of Regression Task***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data set of Tips\n",
    "df = sns.load_dataset('tips') # Load data set of tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip     sex smoker  day    time  size\n",
       "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
       "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
       "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
       "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
       "4       24.59  3.61  Female     No  Sun  Dinner     4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5) # show first 5 rows of data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split tha data into x and y\n",
    "x = df.drop('tip',axis=1)\n",
    "y = df['tip']\n",
    "\n",
    "# Label encode the categorical data\n",
    "le = LabelEncoder()\n",
    "df['sex'] = le.fit_transform(x['sex'])\n",
    "df['smoker'] = le.fit_transform(x['smoker'])\n",
    "df['day'] = le.fit_transform(x['day'])\n",
    "df['time'] = le.fit_transform(x['time'])\n",
    "                              \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Task\n",
    "## 01. Mean Absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "LinearRegression is trained.\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "SVR is trained.\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "DecisionTreeRegressor is trained.\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "RandomForestRegressor is trained.\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "KNeighborsRegressor is trained.\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "GradientBoostingRegressor is trained.\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "XGBRegressor is trained.\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "AdaBoostRegressor is trained.\n",
      "mse for LinearRegression is  0.98\n",
      "mse for SVR is  0.98\n",
      "mse for DecisionTreeRegressor is  0.98\n",
      "mse for RandomForestRegressor is  0.98\n",
      "mse for KNeighborsRegressor is  0.98\n",
      "mse for GradientBoostingRegressor is  0.98\n",
      "mse for XGBRegressor is  0.98\n",
      "mse for AdaBoostRegressor is  0.98\n",
      "\n",
      "\n",
      "mae for LinearRegression is  0.69\n",
      "mae for SVR is  1.46\n",
      "mae for DecisionTreeRegressor is  0.88\n",
      "mae for RandomForestRegressor is  0.96\n",
      "mae for KNeighborsRegressor is  0.61\n",
      "mae for GradientBoostingRegressor is  0.81\n",
      "mae for XGBRegressor is  0.66\n",
      "mae for AdaBoostRegressor is  0.96\n",
      "R-2 score for LinearRegression is 0.67\n",
      "R-2 score for SVR is 0.89\n",
      "R-2 score for DecisionTreeRegressor is 0.72\n",
      "R-2 score for RandomForestRegressor is 0.78\n",
      "R-2 score for KNeighborsRegressor is 0.61\n",
      "R-2 score for GradientBoostingRegressor is 0.77\n",
      "R-2 score for XGBRegressor is 0.65\n",
      "R-2 score for AdaBoostRegressor is 0.78\n",
      "\n",
      "\n",
      "The best model is KNeighborsRegressor\n",
      "CPU times: total: 8.59 s\n",
      "Wall time: 9.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Split tha data into train and test\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "\n",
    "\n",
    "# Create the list of models to be used for Regressor\n",
    "models = { \n",
    "          'LinearRegression' : (LinearRegression(), {}),\n",
    "          'SVR' : (SVR(), {'kernel': ['rbf', 'poly', 'sigmoid']}),\n",
    "          'DecisionTreeRegressor' : (DecisionTreeRegressor(random_state=42), {'max_depth': [None, 5, 10]}),\n",
    "          'RandomForestRegressor' : (RandomForestRegressor(random_state=42), {'n_estimators': [10, 100]}),\n",
    "          'KNeighborsRegressor' : (KNeighborsRegressor(), {'n_neighbors': np.arange(3, 100, 2)}),\n",
    "          'GradientBoostingRegressor' : (GradientBoostingRegressor(random_state=42),{'n_estimators': [10, 100]}),\n",
    "          'XGBRegressor' : (XGBRegressor(), {'n_estimators': [10, 100]}),  \n",
    "          'AdaBoostRegressor': (AdaBoostRegressor(random_state=42), {'n_estimators': [10, 100]}),        \n",
    "          }\n",
    "\n",
    "# Train and predict each model using for loop to itrate through the models\n",
    "model_scores = []\n",
    "for name, (model,params) in models.items():\n",
    "\n",
    "    # Create Pipe line\n",
    "    pipeline = RandomizedSearchCV(model, params, cv=5, n_iter=20, verbose=1, n_jobs=1)\n",
    "\n",
    "    # fit each model on training data\n",
    "    pipeline.fit(x_train,y_train)\n",
    "    # Make prdictions on each model\n",
    "    y_pred = pipeline.predict(x_test)\n",
    "\n",
    "    # Metrics\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    best_parameter = pipeline.best_params_\n",
    "    \n",
    "    # Append the model name and evaluation metrics in list\n",
    "    model_scores.append((name,mae,mse,rmse,best_parameter))\n",
    "    \n",
    "    print(f\"{name} is trained.\")\n",
    "# selecting the best model from all above models with evaluation metrics sorting method\n",
    "sorted_models = sorted(model_scores, key=lambda x: x[1], reverse=False)\n",
    "\n",
    "# printing Each model with evaluation metrics\n",
    "for model in model_scores:\n",
    "    print('mse for', f\"{model[0]} is {model[3]: .2f}\")\n",
    "print('\\n')\n",
    "for model in model_scores:\n",
    "    print('mae for', f\"{model[0]} is {model[2]: .2f}\")\n",
    "\n",
    "for model in model_scores:\n",
    "    print('R-2 score for', f\"{model[0]} is {model[1]:.2f}\")\n",
    "print('\\n')\n",
    "# Selecting the best model\n",
    "best_model = sorted_models[0][0]\n",
    "print(f\"The best model is {best_model}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***I can Perform Regression Task on tips data.... now we can find the Mean abosulate error..IN all of these `Decision Tree Regressor` error is  `83%`... All of these is best model `SVR` Because is error 57%\n",
    "\n",
    "In summary, for regression tasks:\n",
    "\n",
    "Smaller Mean Squared Error (MSE): Indicates better model performance.\n",
    "Larger Mean Squared Error (MSE): Indicates poorer model performance.\n",
    "Select the regressor that achieves the lowest mean squared error on your validation or test set.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii. R_squared Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_squared Score Support Vector Regressor is  0.57\n",
      "R_squared Score Linear Regression is  0.67\n",
      "R_squared Score XGBoost Regressor is  0.67\n",
      "R_squared Score Gradient Boosting Regressor is  0.73\n",
      "R_squared Score KNeighbors Regressor is  0.73\n",
      "R_squared Score Random Forest Regressor is  0.77\n",
      "R_squared Score Decision Tree Regressor is  0.92\n",
      "CPU times: total: 531 ms\n",
      "Wall time: 428 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R_squared Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>0.921837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>0.768749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighbors Regressor</td>\n",
       "      <td>0.726245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boosting Regressor</td>\n",
       "      <td>0.725536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>0.672170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.670381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support Vector Regressor</td>\n",
       "      <td>0.570710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model  R_squared Score\n",
       "1      Decision Tree Regressor         0.921837\n",
       "2      Random Forest Regressor         0.768749\n",
       "4         KNeighbors Regressor         0.726245\n",
       "6  Gradient Boosting Regressor         0.725536\n",
       "5            XGBoost Regressor         0.672170\n",
       "0            Linear Regression         0.670381\n",
       "3     Support Vector Regressor         0.570710"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Split tha data into train and test\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "\n",
    "\n",
    "# Create the list of models to be used for Regressor\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree Regressor': DecisionTreeRegressor(),\n",
    "    'Random Forest Regressor': RandomForestRegressor(),\n",
    "    'Support Vector Regressor': SVR(),\n",
    "    'KNeighbors Regressor': KNeighborsRegressor(),\n",
    "    'XGBoost Regressor': XGBRegressor(),\n",
    "    'Gradient Boosting Regressor': GradientBoostingRegressor(),\n",
    "    # 'Ada Boost Regressor': AdaBoostRegressor()\n",
    "}\n",
    "\n",
    "# Train and predict each model using for loop to itrate through the models\n",
    "model_scores = []\n",
    "for name, model in models.items():\n",
    "    # fit each model on training data\n",
    "    model.fit(x_train,y_train)\n",
    "    # Make prdictions on each model\n",
    "    y_pred = model.predict(x_test)\n",
    "    metric = mean_absolute_error(y_test, y_pred)\n",
    "    model_scores.append((name, metric))\n",
    "\n",
    " \n",
    "\n",
    "# selecting the best model from all above models with evaluation metrics sorting method\n",
    "sorted_models = sorted(model_scores, key=lambda x: x[1], reverse=False)\n",
    "for model in sorted_models:\n",
    "    print('R_squared Score', f\"{model[0]} is {model[1]: .2f}\") \n",
    "\n",
    "\n",
    "\n",
    "# Select the best model with R_squared Score\n",
    "model_scores = pd.DataFrame(model_scores, columns=['Model', 'R_squared Score'])\n",
    "model_scores.sort_values(by='R_squared Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The R-squared score ranges from 0 to 1, where 1 indicates a perfect fit, and 0 indicates that the model does not explain any variability in the target variable.\n",
    "\n",
    "- In general:\n",
    "\n",
    " `Closer to 1`: Indicates a better fit of the model, suggesting that a larger proportion of the variance in the dependent variable is explained by the independent variables.\n",
    " `Closer to 0`: Indicates that the model does not explain much of the variance in the dependent variable.\n",
    " So, when evaluating regression models based on R-squared:\n",
    "\n",
    " - In summary, for regression tasks:\n",
    "\n",
    "`Higher R-squared Score`: Indicates better model performance.\n",
    "`Lower R-squared Score`: Indicates poorer model performance.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iii. Mean Squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared error Support Vector Regressor is  0.57\n",
      "Mean Squared error Linear Regression is  0.67\n",
      "Mean Squared error XGBoost Regressor is  0.67\n",
      "Mean Squared error KNeighbors Regressor is  0.73\n",
      "Mean Squared error Gradient Boosting Regressor is  0.73\n",
      "Mean Squared error Random Forest Regressor is  0.75\n",
      "Mean Squared error Decision Tree Regressor is  0.90\n",
      "CPU times: total: 484 ms\n",
      "Wall time: 429 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean Squared error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>0.896122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>0.754386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boosting Regressor</td>\n",
       "      <td>0.730600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighbors Regressor</td>\n",
       "      <td>0.726245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>0.672170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.670381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support Vector Regressor</td>\n",
       "      <td>0.570710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model  Mean Squared error\n",
       "1      Decision Tree Regressor            0.896122\n",
       "2      Random Forest Regressor            0.754386\n",
       "6  Gradient Boosting Regressor            0.730600\n",
       "4         KNeighbors Regressor            0.726245\n",
       "5            XGBoost Regressor            0.672170\n",
       "0            Linear Regression            0.670381\n",
       "3     Support Vector Regressor            0.570710"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Split tha data into train and test\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "\n",
    "\n",
    "# Create the list of models to be used for Regressor\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree Regressor': DecisionTreeRegressor(),\n",
    "    'Random Forest Regressor': RandomForestRegressor(),\n",
    "    'Support Vector Regressor': SVR(),\n",
    "    'KNeighbors Regressor': KNeighborsRegressor(),\n",
    "    'XGBoost Regressor': XGBRegressor(),\n",
    "    'Gradient Boosting Regressor': GradientBoostingRegressor(),\n",
    "    # 'Ada Boost Regressor': AdaBoostRegressor()\n",
    "}\n",
    "\n",
    "# Train and predict each model using for loop to itrate through the models\n",
    "model_scores = []\n",
    "for name, model in models.items():\n",
    "    # fit each model on training data\n",
    "    model.fit(x_train,y_train)\n",
    "    # Make prdictions on each model\n",
    "    y_pred = model.predict(x_test)\n",
    "    metric = mean_absolute_error(y_test, y_pred)\n",
    "    model_scores.append((name, metric))\n",
    "\n",
    "\n",
    "# selecting the best model from all above models with evaluation metrics sorting method\n",
    "sorted_models = sorted(model_scores, key=lambda x: x[1], reverse=False)\n",
    "for model in sorted_models:\n",
    "    print('Mean Squared error', f\"{model[0]} is {model[1]: .2f}\") \n",
    "\n",
    "\n",
    "\n",
    "# Select the best model with Mean Squared error\n",
    "model_scores = pd.DataFrame(model_scores, columns=['Model', 'Mean Squared error'])\n",
    "model_scores.sort_values(by='Mean Squared error', ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to select the regressor that achieves the smallest mean squared error on the validation or test set. Smaller values of MSE indicate that the predicted values are closer to the actual values, suggesting better accuracy and performance of the model.\n",
    "\n",
    "- In summary, for regression tasks:\n",
    "\n",
    "`Smaller Mean Squared Error (MSE)`: Indicates better model performance.\n",
    "\n",
    "`Larger Mean Squared Error (MSE)`: Indicates poorer model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperpereamter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n",
      "r2_score:  0.4441368826121931\n",
      "mean_squared_error:  0.6948129686287711\n",
      "mean_absolute_error:  0.6703807496461157\n",
      "root_mean_squared_error:  0.8335544185167343\n",
      "--------------------------------------\n",
      "\n",
      "SVR\n",
      "r2_score:  -0.1686013018011976\n",
      "mean_squared_error:  1.460718141299992\n",
      "mean_absolute_error:  0.8935334948775431\n",
      "root_mean_squared_error:  1.2086017298101108\n",
      "--------------------------------------\n",
      "\n",
      "DecisionTreeRegressor\n",
      "r2_score:  0.2980516670532911\n",
      "mean_squared_error:  0.8774153020453991\n",
      "mean_absolute_error:  0.7189481629481629\n",
      "root_mean_squared_error:  0.9367044902451355\n",
      "--------------------------------------\n",
      "\n",
      "RandomForestRegressor\n",
      "r2_score:  0.2299337514142753\n",
      "mean_squared_error:  0.9625607446938791\n",
      "mean_absolute_error:  0.7750510204081635\n",
      "root_mean_squared_error:  0.9811018013916186\n",
      "--------------------------------------\n",
      "\n",
      "KNeighborsRegressor\n",
      "r2_score:  0.4687117753876745\n",
      "mean_squared_error:  0.6640950568462677\n",
      "mean_absolute_error:  0.6203721488595437\n",
      "root_mean_squared_error:  0.8149202763744854\n",
      "--------------------------------------\n",
      "\n",
      "GradientBoostingRegressor\n",
      "r2_score:  0.35144101065487676\n",
      "mean_squared_error:  0.8106801524004932\n",
      "mean_absolute_error:  0.7657809818712309\n",
      "root_mean_squared_error:  0.9003777831557669\n",
      "--------------------------------------\n",
      "\n",
      "XGBRegressor\n",
      "r2_score:  0.4700592836840687\n",
      "mean_squared_error:  0.6624107100882575\n",
      "mean_absolute_error:  0.6549163442728472\n",
      "root_mean_squared_error:  0.8138861775999501\n",
      "--------------------------------------\n",
      "\n",
      "CPU times: total: 2.61 s\n",
      "Wall time: 2.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create a dictionaries of list of models to evaluate performance with all hyperparametes\n",
    "models = { \n",
    "          'LinearRegression' : (LinearRegression(), {}),\n",
    "          'SVR' : (SVR(), {'kernel': ['rbf', 'poly', 'sigmoid'] , 'epsilon': [0.1, 0.2, 0.3]}),\n",
    "          'DecisionTreeRegressor' : (DecisionTreeRegressor(random_state=42), {'max_depth': [None, 5, 10]}),\n",
    "          'RandomForestRegressor' : (RandomForestRegressor(random_state=42), {'n_estimators': [10, 100]}),\n",
    "          'KNeighborsRegressor' : (KNeighborsRegressor(), {'n_neighbors': np.arange(3, 100, 2)}),\n",
    "          'GradientBoostingRegressor' : (GradientBoostingRegressor(), {'n_estimators': [10, 100]}),\n",
    "          'XGBRegressor' : (XGBRegressor(), {'n_estimators': [10, 100]}),          \n",
    "          }\n",
    "\n",
    "# train and predict each model with evaluation metrics as well making a for loop to iterate over the models\n",
    "for name, (model, params) in models.items():\n",
    "    # create a pipline\n",
    "    pipeline = GridSearchCV(model, params, cv=3)\n",
    "\n",
    "    # fit the pipeline\n",
    "    pipeline.fit(x_train, y_train)\n",
    "\n",
    "    # make predictions\n",
    "    y_pred = pipeline.predict(x_test)\n",
    "\n",
    "    # evaluate the model\n",
    "    print(name)\n",
    "    print('r2_score: ',r2_score(y_test,y_pred))\n",
    "    print('mean_squared_error: ',mean_squared_error(y_test,y_pred))\n",
    "    print('mean_absolute_error: ',mean_absolute_error(y_test,y_pred))\n",
    "    print('root_mean_squared_error: ',np.sqrt(mean_squared_error(y_test,y_pred)))\n",
    "    print('--------------------------------------\\n')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine which model is the best among the Linear Regression, Support Vector Regressor (SVR), Decision Tree Regressor, and Random Forest Regressor, you can consider multiple metrics. In the output you provided, the key metrics are R² score, Mean Squared Error (MSE), Mean Absolute Error (MAE), and Root Mean Squared Error (RMSE). Let's briefly interpret these metrics:\n",
    "\n",
    "1. **R² Score:**\n",
    "   - **Higher R² Score:** Indicates a better fit of the model.\n",
    "   - **Interpretation:** The percentage of the variance in the target variable that is explained by the model. Closer to 1 is better.\n",
    "\n",
    "2. **Mean Squared Error (MSE):**\n",
    "   - **Smaller MSE:** Indicates better accuracy and performance.\n",
    "   - **Interpretation:** The average squared difference between the predicted and actual values. Smaller values are better.\n",
    "\n",
    "3. **Mean Absolute Error (MAE):**\n",
    "   - **Smaller MAE:** Indicates better accuracy and performance.\n",
    "   - **Interpretation:** The average absolute difference between the predicted and actual values. Smaller values are better.\n",
    "\n",
    "4. **Root Mean Squared Error (RMSE):**\n",
    "   - **Smaller RMSE:** Indicates better accuracy and performance.\n",
    "   - **Interpretation:** The square root of the average squared difference between the predicted and actual values. Smaller values are better.\n",
    "\n",
    "Now, let's analyze the provided metrics:\n",
    "\n",
    "- **Linear Regression:**\n",
    "  - R² Score: 0.44\n",
    "  - MSE: 0.69\n",
    "  - MAE: 0.67\n",
    "  - RMSE: 0.83\n",
    "\n",
    "- **SVR:**\n",
    "  - R² Score: -0.17\n",
    "  - MSE: 1.46\n",
    "  - MAE: 0.89\n",
    "  - RMSE: 1.21\n",
    "\n",
    "- **Decision Tree Regressor:**\n",
    "  - R² Score: 0.30\n",
    "  - MSE: 0.88\n",
    "  - MAE: 0.72\n",
    "  - RMSE: 0.94\n",
    "\n",
    "- **Random Forest Regressor:**\n",
    "  - R² Score: 0.23\n",
    "  - MSE: 0.96\n",
    "  - MAE: 0.78\n",
    "  - RMSE: 0.98\n",
    "\n",
    "Based on these metrics:\n",
    "\n",
    "- **Linear Regression** has the highest R² score (0.44), indicating a relatively better fit compared to other models.\n",
    "- **Decision Tree Regressor** has a decent R² score (0.30) and lower MSE, MAE, and RMSE compared to the other models.\n",
    "- **Random Forest Regressor** also performs reasonably well, but with a slightly lower R² score compared to Linear Regression and Decision Tree.\n",
    "\n",
    "It's essential to consider the specific requirements of your problem and the trade-offs between metrics. In this case, Linear Regression might be considered the best among the models based on R² score. However, depending on your specific goals and the nature of your data, you might choose a different model. Consider the overall context and any business or problem-specific considerations when making your final decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You code should also save the best model in the pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model into pickle file\n",
    "import pickle\n",
    "pickle.dump(model,open('../Project/model.pkl','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model using joblib\n",
    "joblib.dump(model, 'linear_regression_model.joblib')\n",
    "\n",
    "# Load the model using joblib\n",
    "loaded_model = joblib.load('linear_regression_model.joblib')\n",
    "\n",
    "# Use the loaded model to make predictions\n",
    "predictions = loaded_model.predict(X_test)\n",
    "\n",
    "print(\"Predictions:\", predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import classification metrics and libraries\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import seaborn as sns\n",
    "\n",
    "# dn't show warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data set of diamonds\n",
    "df = sns.load_dataset('iris')\n",
    "df.head(5) # show first 5 rows of data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split tha data into x and y\n",
    "x = df.drop('species',axis=1)\n",
    "y = df['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: Logistic Regression\n",
      "Mean Accuracy: 0.9733333333333334\n",
      "\n",
      "model: Decision Tree Classifier\n",
      "Mean Accuracy: 0.9533333333333335\n",
      "\n",
      "model: Random Forest Classifier\n",
      "Mean Accuracy: 0.9600000000000002\n",
      "\n",
      "CPU times: total: 2.48 s\n",
      "Wall time: 3.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Split tha data into train and test data set with 80% train and 20% test\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "\n",
    "# Create a dictionaries of list of  classification models to evaluate performance\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree Classifier': DecisionTreeClassifier(),\n",
    "    'Random Forest Classifier': RandomForestClassifier(),\n",
    "    # 'Support Vector Classifier': SVC(),\n",
    "    # 'KNeighbors Classifier': KNeighborsClassifier(),\n",
    "}\n",
    "\n",
    "# perform k-fold cross validation\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, x, y, cv=kfold)\n",
    "    accuracy = np.mean(scores)\n",
    "    print(\"model:\", name)\n",
    "    print(\"Mean Accuracy:\", accuracy)\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \n",
    "It seems like you have worked on three models on dataset of iris because our laptop doesn't have enough capacity, and running them is taking a lot of time on diamond dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperperameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "accuracy_score:  1.0\n",
      "precision_score:  1.0\n",
      "recall_score:  1.0\n",
      "f1_score:  1.0\n",
      "--------------------------------------\n",
      "\n",
      "Decision Tree Classifier\n",
      "accuracy_score:  1.0\n",
      "precision_score:  1.0\n",
      "recall_score:  1.0\n",
      "f1_score:  1.0\n",
      "--------------------------------------\n",
      "\n",
      "Random Forest Classifier\n",
      "accuracy_score:  1.0\n",
      "precision_score:  1.0\n",
      "recall_score:  1.0\n",
      "f1_score:  1.0\n",
      "--------------------------------------\n",
      "\n",
      "Support Vector Classifier\n",
      "accuracy_score:  1.0\n",
      "precision_score:  1.0\n",
      "recall_score:  1.0\n",
      "f1_score:  1.0\n",
      "--------------------------------------\n",
      "\n",
      "KNeighbors Classifier\n",
      "accuracy_score:  1.0\n",
      "precision_score:  1.0\n",
      "recall_score:  1.0\n",
      "f1_score:  1.0\n",
      "--------------------------------------\n",
      "\n",
      "CPU times: total: 5.45 s\n",
      "Wall time: 6.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create a dictionaries of list of  classification models to evaluate performance with all hyperparametes\n",
    "models = {\n",
    "    'Logistic Regression': (LogisticRegression(), {}),\n",
    "    'Decision Tree Classifier': (DecisionTreeClassifier(random_state=42), {'max_depth': [None, 5, 10]}),\n",
    "    'Random Forest Classifier': (RandomForestClassifier(random_state=42), {'n_estimators': [10, 100]}),\n",
    "    'Support Vector Classifier': (SVC(),{}),\n",
    "    'KNeighbors Classifier': (KNeighborsClassifier(), {'n_neighbors': np.arange(3, 100, 2)}),\n",
    "}\n",
    "\n",
    "# train and predict each model with evaluation metrics as well making a for loop to iterate over the models\n",
    "for name, (model, params) in models.items():\n",
    "    # create a pipline\n",
    "    pipeline = GridSearchCV(model, params, cv=3)\n",
    "\n",
    "    # fit the pipeline\n",
    "    pipeline.fit(x_train, y_train)\n",
    "\n",
    "    # make predictions\n",
    "    y_pred = pipeline.predict(x_test)\n",
    "\n",
    "    # evaluate the model\n",
    "    print(name)\n",
    "    print('accuracy_score: ',accuracy_score(y_test,y_pred))\n",
    "    print('precision_score: ',precision_score(y_test,y_pred,average='micro'))\n",
    "    print('recall_score: ',recall_score(y_test,y_pred,average='micro'))\n",
    "    print('f1_score: ',f1_score(y_test,y_pred,average='micro'))\n",
    "    print('--------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model into pickle file\n",
    "import pickle\n",
    "pickle.dump(model,open('../Project/classification model.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
